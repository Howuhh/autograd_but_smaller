{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import autograd.tensor as tensor\n",
    "import autograd.nn as nn\n",
    "\n",
    "from autograd.optim import SGD\n",
    "from autograd.validation import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "### Forward mode & dual numbers\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Dual_number\n",
    "- https://blog.demofox.org/2014/12/30/dual-numbers-automatic-differentiation/\n",
    "- https://blog.demofox.org/2017/02/20/multivariable-dual-numbers-automatic-differentiation/\n",
    "- https://marksaroufim.medium.com/automatic-differentiation-step-by-step-24240f97a6e6\n",
    "\n",
    "### Backward mode & backpropagation\n",
    "\n",
    "- https://www.jmlr.org/papers/volume18/17-468/17-468.pdf\n",
    "- https://sidsite.com/posts/autodiff/\n",
    "- https://github.com/karpathy/micrograd\n",
    "\n",
    "### More on derivatives\n",
    "\n",
    "- http://cs231n.stanford.edu/vecDerivs.pdf\n",
    "- http://cs231n.stanford.edu/handouts/linear-backprop.pdf\n",
    "- https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegNet(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(in_shape, 32)\n",
    "        self.l2 = nn.Linear(32, 1)\n",
    "                    \n",
    "    def forward(self, X):\n",
    "        out = self.l1(X).relu()\n",
    "        return self.l2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X_, y_ = load_boston()[\"data\"], load_boston()[\"target\"]\n",
    "X, y = tensor.Tensor(X_), tensor.Tensor(y_).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.873600637551323\n"
     ]
    }
   ],
   "source": [
    "net = SimpleRegNet(X.shape[1])\n",
    "optimizer = SGD(net.parameters(), lr=1e-6)\n",
    "\n",
    "for i in range(500):\n",
    "    net.zero_grad()\n",
    "        \n",
    "    loss = MSELoss(net(X), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(np.sqrt(loss.value[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}